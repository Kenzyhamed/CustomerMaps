# -*- coding: utf-8 -*-
"""Copy of multimodal_embedding_requires_premade_dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s3g7i5QzA8WRG5QCMKFhBeVCKDwJaJHn

# Vertex AI Embeddings - Text & Multimodal

### Objectives

* Vertex AI Multimodal Embeddings API (Texts, Images & Video)
* Building simple search with e-commerce data
    - Find product based on text query
    - Find product based on image

Make sure the regular custom_marks_data.csv file is uploaded to this colab session or stored locally if running on VSC

## Getting Started

### Install Vertex AI SDK for Python and other dependencies
"""

! pip3 install --upgrade --user google-cloud-aiplatform
! pip3 install --upgrade --user google-cloud-storage
! pip3 install --upgrade --user requests

"""### Restart current runtime

To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel.
"""

# Restart kernel after installs so that your environment can access the new packages
import IPython

app = IPython.Application.instance()
app.kernel.do_shutdown(True)

"""<div class="alert alert-block alert-warning">
<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>
</div>

### Authenticate your notebook environment (Colab only)

If you are running this notebook on Google Colab, run the following cell to authenticate your environment. This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench).
"""

import sys

# Additional authentication is required for Google Colab
if "google.colab" in sys.modules:
    #Authenticate user to Google Cloud
    from google.colab import auth

    auth.authenticate_user()

"""### Set Google Cloud project information and initialize Vertex AI SDK

To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).

Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment).
"""

# Define project information

import sys

# if not running on Colab, try to get the PROJECT_ID automatically
if "google.colab" not in sys.modules:
    import subprocess

    PROJECT_ID = subprocess.check_output(
        ["gcloud", "config", "get-value", "project"], text=True
    ).strip()
else:
    PROJECT_ID = "tutorial-project-437116"  # @param {type:"string"}
LOCATION = "us-central1"

print(f"Your project ID is: {PROJECT_ID}")

import sys

# Initialize Vertex AI
import vertexai

vertexai.init(project=PROJECT_ID, location=LOCATION)

"""### Import libraries"""

# for image processing

# for data processing
import numpy as np
import pandas as pd

pd.options.mode.chained_assignment = None  # default='warn'

# for showing images and videos
from IPython.display import HTML
from IPython.display import Image as ImageByte
from IPython.display import display

# vertex ai sdk
import vertexai
from vertexai.vision_models import Image as VMImage
from vertexai.vision_models import MultiModalEmbeddingModel
from vertexai.vision_models import Video as VMVideo
from vertexai.vision_models import VideoSegmentConfig

"""### Load Vertex AI Text and Multimodal Embeddings"""

mm_embedding_model = MultiModalEmbeddingModel.from_pretrained("multimodalembedding")

"""### Load and Test an Embedding Case"""

def get_image_embedding(
    image_path: str = None,
    dimension: int | None = 1408,
) -> list[float]:
    image = VMImage.load_from_file(image_path)
    embedding = mm_embedding_model.get_embeddings(
        image=image,
        dimension=dimension,
    )
    return embedding.image_embedding

def get_public_url_from_gcs(gcs_uri: str) -> str:
    return gcs_uri.replace("gs://", "https://storage.googleapis.com/").replace(
        " ", "%20"
    )

# Image embeddings with default 1408 dimension
image_path = "gs://umair_bucket_retail_1/dh-1-4-zip-pullover-a5cd9a45-66ab-42b1-bd36-7e6f4225ef90-jpgrendition.jpg"
print(get_public_url_from_gcs(image_path))

image_emb = get_image_embedding(
    image_path=image_path,
)

"""### Extract Embeddings to a new CSV File"""

def get_text_embedding(
    text: str = "apple muffins",
    dimension: int | None = 1408,
) -> list[float]:
    embedding = mm_embedding_model.get_embeddings(
        contextual_text=text,
        dimension=dimension,
    )
    return embedding.text_embedding

# Function to process image embeddings (from your earlier code)
def process_row(row):
    try:
        embedding = get_image_embedding(image_path=row["gcs_path"])
        return embedding
    except Exception as e:
        print(f"Error processing row {row.name}: {e}")
        return None

# Function to process text embeddings (corrected)
def process_text_row(row):
    try:
        embedding = get_text_embedding(text=row["combined_text"])
        return embedding
    except Exception as e:
        print(f"Error processing row {row.name}: {e}")
        return None

# Load the CSV file
csv_file = "custom_marks_data.csv"
df = pd.read_csv(csv_file)

# Apply the embedding generation functions
df["image_embeddings"] = df.apply(process_row, axis=1)
df["text_embeddings"] = df.apply(process_text_row, axis=1)

# Save to a NEW CSV file
new_csv_file = "updated_embeddings.csv"
df.to_csv(new_csv_file, index=False)

print(f"Embeddings (image and text) saved to: {new_csv_file}")

"""### Find product images based on text search query"""

# get product list with pre-computed image embeddings
product_image_list = pd.read_csv("updated_embeddings.csv")

def get_similar_products(query_emb, data_frame):
    # calc dot product
    image_embs = data_frame["image_embeddings"]
    scores = [np.dot(eval(image_emb), query_emb) for image_emb in image_embs]
    data_frame["score"] = scores
    data_frame = data_frame.sort_values(by="score", ascending=False)

    top_results = data_frame.head()[["score", "combined_text", "img_url"]]

    # Convert the results to a dictionary
    results = top_results.to_dict(orient="records")

    return results

# calc_scores for a text query
query_emb = get_text_embedding("short sleeves")
get_similar_products(query_emb, product_image_list)



